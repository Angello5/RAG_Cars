{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:45:40.696128Z",
     "start_time": "2025-08-10T21:45:40.641665Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs detectados: 2\n",
      " 1. /Users/angellollerena/Documents/GitHub/RAG_Cars/Volkswagen/Ficha-Tecnica-Amarok-2025.pdf | exists=True\n",
      " 2. /Users/angellollerena/Documents/GitHub/RAG_Cars/Toyota/CATALOGO_COROLLA_PERU.pdf | exists=True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from langchain_core import documents\n",
    "\n",
    "BASE = Path(\"/Users/angellollerena/Documents/GitHub/RAG_Cars\")\n",
    "PDF_DIR = BASE\n",
    "PROCESSED_DIR = BASE / \"data\" / \"processed\"\n",
    "INDEX_DIR = BASE / \"index\" / \"chroma_autos\"\n",
    "\n",
    "for p in [PROCESSED_DIR, INDEX_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SKIP_DIR_NAMES = {\"data\", \"index\", \".git\", \".ipynb_checkpoints\", \".idea\", \".venv\", \"env\", \"venv\"}\n",
    "\n",
    "def should_skip(path: Path) -> bool:\n",
    "    return any(part.startswith(\".\") or part in SKIP_DIR_NAMES for part in path.parts)\n",
    "\n",
    "# Descubrir PDFs\n",
    "candidates = []\n",
    "for p in PDF_DIR.rglob(\"*.pdf\"):\n",
    "    if should_skip(p):\n",
    "        continue\n",
    "    if PROCESSED_DIR in p.parents:\n",
    "        continue\n",
    "    candidates.append(p.resolve())\n",
    "\n",
    "print(\"PDFs detectados:\", len(candidates))\n",
    "for i, p in enumerate(candidates, 1):\n",
    "    print(f\"{i:>2}. {p} | exists={p.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "607970b413e548db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:25.073683Z",
     "start_time": "2025-08-10T21:45:40.817050Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angellollerena/miniforge3/envs/pruebas/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-26 00:19:22,859 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-26 00:19:22,893 - INFO - Going to convert document batch...\n",
      "2025-12-26 00:19:22,894 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2025-12-26 00:19:22,900 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-26 00:19:22,902 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-12-26 00:19:22,908 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-26 00:19:22,911 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-12-26 00:19:24,165 - INFO - Auto OCR model selected ocrmac.\n",
      "2025-12-26 00:19:24,170 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-26 00:19:24,173 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2025-12-26 00:19:24,177 - INFO - Accelerator device: 'mps'\n",
      "2025-12-26 00:19:25,171 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-26 00:19:25,173 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2025-12-26 00:19:27,329 - INFO - Accelerator device: 'mps'\n",
      "2025-12-26 00:19:27,952 - INFO - Processing document CATALOGO_COROLLA_PERU.pdf\n",
      "2025-12-26 00:19:46,567 - INFO - Finished converting document CATALOGO_COROLLA_PERU.pdf in 23.70 sec.\n",
      "2025-12-26 00:19:46,636 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-26 00:19:46,660 - INFO - Going to convert document batch...\n",
      "2025-12-26 00:19:46,661 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2025-12-26 00:19:46,662 - INFO - Auto OCR model selected ocrmac.\n",
      "2025-12-26 00:19:46,662 - INFO - Accelerator device: 'mps'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ docling  Toyota/CATALOGO_COROLLA_PERU.pdf -> data/processed/Toyota/CATALOGO_COROLLA_PERU.md (31159 chars)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-26 00:19:47,573 - INFO - Accelerator device: 'mps'\n",
      "2025-12-26 00:19:48,106 - INFO - Processing document Ficha-Tecnica-Amarok-2025.pdf\n",
      "2025-12-26 00:19:58,807 - INFO - Finished converting document Ficha-Tecnica-Amarok-2025.pdf in 12.17 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ docling  Volkswagen/Ficha-Tecnica-Amarok-2025.pdf -> data/processed/Volkswagen/Ficha-Tecnica-Amarok-2025.md (41235 chars)\n",
      "\n",
      "Listo. 2 PDFs procesados.\n"
     ]
    }
   ],
   "source": [
    "import json,os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "SKIP_DIR_NAMES = {\"data\", \"index\", \".git\", \".ipynb_checkpoints\", \".idea\", \".venv\", \"env\", \"venv\"}\n",
    "\n",
    "class ParseResult(BaseModel):\n",
    "    pdf_path: str\n",
    "    md_path: str\n",
    "    json_meta_path: str\n",
    "    chars : int\n",
    "    used : str   #docling\n",
    "\n",
    "def rel_to_base(path: Path, base: Path) -> Path:\n",
    "    # Devuelve path relativo a base sin reventar si no es subpath directo\n",
    "    try:\n",
    "        return path.relative_to(base)\n",
    "    except Exception:\n",
    "        return Path(os.path.relpath(path, base))\n",
    "\n",
    "def convert_pdf_docling(pdf_path : Path):\n",
    "    conv = DocumentConverter()\n",
    "    res = conv.convert(str(pdf_path))\n",
    "    md_text = res.document.export_to_markdown()\n",
    "    meta = res.document.as_dict() if hasattr(res.document, \"as_dict\") else {\"note\":\"no-as_dict\"}\n",
    "    return md_text, meta\n",
    "\n",
    "def convert_pdf(pdf_path : Path,out_md: Path, out_json: Path):\n",
    "    md_text, meta = convert_pdf_docling(pdf_path)\n",
    "    out_md.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out_md.write_text(md_text, encoding=\"utf-8\")\n",
    "    out_json.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    return ParseResult(pdf_path=str(pdf_path), md_path=str(out_md), json_meta_path=str(out_json),\n",
    "                       chars=len(md_text), used=\"docling\")\n",
    "\n",
    "def ingest_all(pdf_list: List[Path], processed_root: Path) -> List[ParseResult]:\n",
    "    results = []\n",
    "    for pdf in sorted(pdf_list):          # <<< iteramos por CADA Path\n",
    "        if not pdf.exists():\n",
    "            print(f\"[WARN] No existe: {pdf}\")\n",
    "            continue\n",
    "        rel = rel_to_base(pdf, PDF_DIR)   # relativo a la raíz del proyecto\n",
    "        out_md = processed_root / rel.with_suffix(\".md\")\n",
    "        out_json = processed_root / rel.with_suffix(\".json\")\n",
    "        r = convert_pdf(pdf, out_md, out_json)\n",
    "        print(f\"✓ docling  {rel} -> data/processed/{rel.with_suffix('.md')} ({r.chars} chars)\")\n",
    "        results.append(r)\n",
    "    return results\n",
    "\n",
    "\n",
    "ingest_summary = ingest_all(candidates, PROCESSED_DIR)\n",
    "print(f\"\\nListo. {len(ingest_summary)} PDFs procesados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c46e4826e8f15c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:25.372334Z",
     "start_time": "2025-08-10T21:46:25.086449Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import torch\n",
    "\n",
    "#ahora viene lo chido\n",
    "def load_md_documents(processed_root: Path):\n",
    "    docs = []\n",
    "    for md in processed_root.rglob(\"*.md\"):\n",
    "        docs.extend(TextLoader(str(md), encoding=\"utf-8\").load())\n",
    "    return docs\n",
    "\n",
    "docs = load_md_documents(PROCESSED_DIR)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=150)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "463bc906ac652142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:25.386638Z",
     "start_time": "2025-08-10T21:46:25.384566Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7debf797841c4f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:29.046768Z",
     "start_time": "2025-08-10T21:46:25.435556Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-26 00:20:00,208 - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs = {\"device\": device}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84eedbfdfcddb50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:30.041649Z",
     "start_time": "2025-08-10T21:46:29.057034Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-26 00:20:25,018 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db = Chroma.from_documents(\n",
    "    documents= chunks,\n",
    "    embedding = embeddings,\n",
    "    persist_directory=str(INDEX_DIR)\n",
    ")\n",
    "#vector_db.persist()\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f033047d2892a2aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:31.211779Z",
     "start_time": "2025-08-10T21:46:30.074923Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "#vector_db = Chroma(persist_directory=str(INDEX_DIR), embedding_function=embeddings) #error de versiones deprecated\n",
    "\n",
    "base_docs = load_md_documents(PROCESSED_DIR)\n",
    "base_chunks = splitter.split_documents(base_docs)\n",
    "bm25 = BM25Retriever.from_documents(base_chunks)\n",
    "bm25.k = 12\n",
    "\n",
    "vec_retriever = vector_db.as_retriever(search_kwargs={\"k\":12})\n",
    "\n",
    "reranker = FlagReranker(\"BAAI/bge-reranker-v2-m3\", use_fp16=(device == \"cuda\"))\n",
    "\n",
    "def retrieve(query: str, topk:int=5):\n",
    "    vec_docs = vec_retriever.get_relevant_documents(query)\n",
    "    bm_docs  = bm25.get_relevant_documents(query)\n",
    "    # merge + dedupe por (contenido corto, fuente)\n",
    "    pool, seen = [], set()\n",
    "    for d in vec_docs + bm_docs:\n",
    "        key = (d.page_content[:200], d.metadata.get(\"source\"))\n",
    "        if key not in seen:\n",
    "            pool.append(d); seen.add(key)\n",
    "    # rerank\n",
    "    pairs = [[query, d.page_content] for d in pool]\n",
    "    scores = reranker.compute_score(pairs, normalize=True)\n",
    "    order = sorted(range(len(pool)), key=lambda i: -scores[i])\n",
    "    return [pool[i] for i in order[:topk]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7187058afd08e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:31.319968Z",
     "start_time": "2025-08-10T21:46:31.221935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='gpt-oss:20b')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model = \"gpt-oss:20b\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db2abfc3b434d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:31.369085Z",
     "start_time": "2025-08-10T21:46:31.333229Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.prompts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[32m      3\u001b[39m PROMPT = ChatPromptTemplate.from_template(\n\u001b[32m      4\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Eres un asesor experto en autos para Perú y responde en Español siempre.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03mResponde SOLO con el contexto. Especifica versión/año si aplica.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[33;03mRespuesta:\"\"\"\u001b[39;00m\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat_sources\u001b[39m(docs):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.prompts'"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Eres un asesor experto en autos para Perú y responde en Español siempre.\n",
    "Responde SOLO con el contexto. Especifica versión/año si aplica.\n",
    "Si no está en el contexto, di claramente que no tienes ese dato.\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "Respuesta:\"\"\"\n",
    ")\n",
    "\n",
    "def format_sources(docs):\n",
    "    out = []\n",
    "    for d in docs:\n",
    "        src = d.metadata.get(\"source\",\"\")\n",
    "        if src:\n",
    "            try:\n",
    "                src_rel = str(Path(src)).replace(str(PROCESSED_DIR)+\"/\", \"\")\n",
    "            except Exception:\n",
    "                src_rel = src\n",
    "            out.append(src_rel)\n",
    "    return list(dict.fromkeys(out))  # únicos\n",
    "\n",
    "def ask(question: str):\n",
    "    docs = retrieve(question, topk=5)\n",
    "    context = \"\\n\\n---\\n\\n\".join(d.page_content[:3000] for d in docs)\n",
    "    msg = PROMPT.format(context=context, question=question)\n",
    "    answer = llm.invoke(msg).content\n",
    "    cites = format_sources(docs)\n",
    "    return answer, cites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768253927cad086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T22:00:03.777404Z",
     "start_time": "2025-08-10T21:57:27.396897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasta 52 litros. \n",
      "\n",
      "Fuentes:\n",
      " - Volkswagen/Ficha-Tecnica-Amarok-2025.md\n",
      " - Toyota/CATALOGO_COROLLA_PERU.md\n"
     ]
    }
   ],
   "source": [
    "q = \"Cual es la capacidad total que tiene para poner GLP en un Toyota Corolla?\"\n",
    "ans, cites = ask(q)\n",
    "print(ans, \"\\n\\nFuentes:\")\n",
    "for c in cites:\n",
    "    print(\" -\", c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pruebas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
