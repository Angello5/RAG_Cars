{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:45:40.696128Z",
     "start_time": "2025-08-10T21:45:40.641665Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs detectados: 2\n",
      " 1. /home/pibezx/Documents/Proyectos/Toyota/CATALOGO_COROLLA_PERU.pdf | exists=True\n",
      " 2. /home/pibezx/Documents/Proyectos/Volkswagen/Ficha-Tecnica-Amarok-2025.pdf | exists=True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from langchain_core import documents\n",
    "\n",
    "BASE = Path(\"/home/pibezx/Documents/Proyectos\")\n",
    "PDF_DIR = BASE\n",
    "PROCESSED_DIR = BASE / \"data\" / \"processed\"\n",
    "INDEX_DIR = BASE / \"index\" / \"chroma_autos\"\n",
    "\n",
    "for p in [PROCESSED_DIR, INDEX_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SKIP_DIR_NAMES = {\"data\", \"index\", \".git\", \".ipynb_checkpoints\", \".idea\", \".venv\", \"env\", \"venv\"}\n",
    "\n",
    "def should_skip(path: Path) -> bool:\n",
    "    return any(part.startswith(\".\") or part in SKIP_DIR_NAMES for part in path.parts)\n",
    "\n",
    "# Descubrir PDFs\n",
    "candidates = []\n",
    "for p in PDF_DIR.rglob(\"*.pdf\"):\n",
    "    if should_skip(p):\n",
    "        continue\n",
    "    if PROCESSED_DIR in p.parents:\n",
    "        continue\n",
    "    candidates.append(p.resolve())\n",
    "\n",
    "print(\"PDFs detectados:\", len(candidates))\n",
    "for i, p in enumerate(candidates, 1):\n",
    "    print(f\"{i:>2}. {p} | exists={p.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607970b413e548db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:25.073683Z",
     "start_time": "2025-08-10T21:45:40.817050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ docling  Toyota/CATALOGO_COROLLA_PERU.pdf -> data/processed/Toyota/CATALOGO_COROLLA_PERU.md (39324 chars)\n",
      "✓ docling  Volkswagen/Ficha-Tecnica-Amarok-2025.pdf -> data/processed/Volkswagen/Ficha-Tecnica-Amarok-2025.md (39315 chars)\n",
      "\n",
      "Listo. 2 PDFs procesados.\n"
     ]
    }
   ],
   "source": [
    "import json,os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "SKIP_DIR_NAMES = {\"data\", \"index\", \".git\", \".ipynb_checkpoints\", \".idea\", \".venv\", \"env\", \"venv\"}\n",
    "\n",
    "class ParseResult(BaseModel):\n",
    "    pdf_path: str\n",
    "    md_path: str\n",
    "    json_meta_path: str\n",
    "    chars : int\n",
    "    used : str   #docling\n",
    "\n",
    "def rel_to_base(path: Path, base: Path) -> Path:\n",
    "    # Devuelve path relativo a base sin reventar si no es subpath directo\n",
    "    try:\n",
    "        return path.relative_to(base)\n",
    "    except Exception:\n",
    "        return Path(os.path.relpath(path, base))\n",
    "\n",
    "def convert_pdf_docling(pdf_path : Path):\n",
    "    conv = DocumentConverter()\n",
    "    res = conv.convert(str(pdf_path))\n",
    "    md_text = res.document.export_to_markdown()\n",
    "    meta = res.document.as_dict() if hasattr(res.document, \"as_dict\") else {\"note\":\"no-as_dict\"}\n",
    "    return md_text, meta\n",
    "\n",
    "def convert_pdf(pdf_path : Path,out_md: Path, out_json: Path):\n",
    "    md_text, meta = convert_pdf_docling(pdf_path)\n",
    "    out_md.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out_md.write_text(md_text, encoding=\"utf-8\")\n",
    "    out_json.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    return ParseResult(pdf_path=str(pdf_path), md_path=str(out_md), json_meta_path=str(out_json),\n",
    "                       chars=len(md_text), used=\"docling\")\n",
    "\n",
    "def ingest_all(pdf_list: List[Path], processed_root: Path) -> List[ParseResult]:\n",
    "    results = []\n",
    "    for pdf in sorted(pdf_list):          # <<< iteramos por CADA Path\n",
    "        if not pdf.exists():\n",
    "            print(f\"[WARN] No existe: {pdf}\")\n",
    "            continue\n",
    "        rel = rel_to_base(pdf, PDF_DIR)   # relativo a la raíz del proyecto\n",
    "        out_md = processed_root / rel.with_suffix(\".md\")\n",
    "        out_json = processed_root / rel.with_suffix(\".json\")\n",
    "        r = convert_pdf(pdf, out_md, out_json)\n",
    "        print(f\"✓ docling  {rel} -> data/processed/{rel.with_suffix('.md')} ({r.chars} chars)\")\n",
    "        results.append(r)\n",
    "    return results\n",
    "\n",
    "\n",
    "ingest_summary = ingest_all(candidates, PROCESSED_DIR)\n",
    "print(f\"\\nListo. {len(ingest_summary)} PDFs procesados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46e4826e8f15c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:25.372334Z",
     "start_time": "2025-08-10T21:46:25.086449Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import torch\n",
    "\n",
    "#ahora viene lo chido\n",
    "def load_md_documents(processed_root: Path):\n",
    "    docs = []\n",
    "    for md in processed_root.rglob(\"*.md\"):\n",
    "        docs.extend(TextLoader(str(md), encoding=\"utf-8\").load())\n",
    "    return docs\n",
    "\n",
    "docs = load_md_documents(PROCESSED_DIR)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=150)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "463bc906ac652142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:25.386638Z",
     "start_time": "2025-08-10T21:46:25.384566Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7debf797841c4f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:29.046768Z",
     "start_time": "2025-08-10T21:46:25.435556Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"intfloat/multilingual-e5-base\",\n",
    "    model_kwargs = {\"device\": device}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f84eedbfdfcddb50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:30.041649Z",
     "start_time": "2025-08-10T21:46:29.057034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db = Chroma.from_documents(\n",
    "    documents= chunks,\n",
    "    embedding = embeddings,\n",
    "    persist_directory=str(INDEX_DIR)\n",
    ")\n",
    "#vector_db.persist()\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f033047d2892a2aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:31.211779Z",
     "start_time": "2025-08-10T21:46:30.074923Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "#vector_db = Chroma(persist_directory=str(INDEX_DIR), embedding_function=embeddings) #error de versiones deprecated\n",
    "\n",
    "base_docs = load_md_documents(PROCESSED_DIR)\n",
    "base_chunks = splitter.split_documents(base_docs)\n",
    "bm25 = BM25Retriever.from_documents(base_chunks)\n",
    "bm25.k = 12\n",
    "\n",
    "vec_retriever = vector_db.as_retriever(search_kwargs={\"k\":12})\n",
    "\n",
    "reranker = FlagReranker(\"BAAI/bge-reranker-v2-m3\", use_fp16=(device == \"cuda\"))\n",
    "\n",
    "def retrieve(query: str, topk:int=5):\n",
    "    vec_docs = vec_retriever.get_relevant_documents(query)\n",
    "    bm_docs  = bm25.get_relevant_documents(query)\n",
    "    # merge + dedupe por (contenido corto, fuente)\n",
    "    pool, seen = [], set()\n",
    "    for d in vec_docs + bm_docs:\n",
    "        key = (d.page_content[:200], d.metadata.get(\"source\"))\n",
    "        if key not in seen:\n",
    "            pool.append(d); seen.add(key)\n",
    "    # rerank\n",
    "    pairs = [[query, d.page_content] for d in pool]\n",
    "    scores = reranker.compute_score(pairs, normalize=True)\n",
    "    order = sorted(range(len(pool)), key=lambda i: -scores[i])\n",
    "    return [pool[i] for i in order[:topk]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7187058afd08e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:31.319968Z",
     "start_time": "2025-08-10T21:46:31.221935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='gpt-oss:20b')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model = \"gpt-oss:20b\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db2abfc3b434d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:46:31.369085Z",
     "start_time": "2025-08-10T21:46:31.333229Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Eres un asesor experto en autos para Perú y responde en Español siempre.\n",
    "Responde SOLO con el contexto. Especifica versión/año si aplica.\n",
    "Si no está en el contexto, di claramente que no tienes ese dato.\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "Respuesta:\"\"\"\n",
    ")\n",
    "\n",
    "def format_sources(docs):\n",
    "    out = []\n",
    "    for d in docs:\n",
    "        src = d.metadata.get(\"source\",\"\")\n",
    "        if src:\n",
    "            try:\n",
    "                src_rel = str(Path(src)).replace(str(PROCESSED_DIR)+\"/\", \"\")\n",
    "            except Exception:\n",
    "                src_rel = src\n",
    "            out.append(src_rel)\n",
    "    return list(dict.fromkeys(out))  # únicos\n",
    "\n",
    "def ask(question: str):\n",
    "    docs = retrieve(question, topk=5)\n",
    "    context = \"\\n\\n---\\n\\n\".join(d.page_content[:3000] for d in docs)\n",
    "    msg = PROMPT.format(context=context, question=question)\n",
    "    answer = llm.invoke(msg).content\n",
    "    cites = format_sources(docs)\n",
    "    return answer, cites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768253927cad086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T22:00:03.777404Z",
     "start_time": "2025-08-10T21:57:27.396897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasta 52 litros. \n",
      "\n",
      "Fuentes:\n",
      " - Volkswagen/Ficha-Tecnica-Amarok-2025.md\n",
      " - Toyota/CATALOGO_COROLLA_PERU.md\n"
     ]
    }
   ],
   "source": [
    "q = \"Cual es la capacidad total que tiene para poner GLP en un Toyota Corolla?\"\n",
    "ans, cites = ask(q)\n",
    "print(ans, \"\\n\\nFuentes:\")\n",
    "for c in cites:\n",
    "    print(\" -\", c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
